apiVersion: "monitoring.coreos.com/v1"
kind: "PrometheusRule"
metadata:
  name: "general-rules"
  namespace: "monitoring"
  labels:
    release: "prom-operator"
spec:
  groups:
    - name: "general-record.rules"
      rules:
        - expr: 'count without(instance, pod, node) (up == 1)'
          record: 'count:up1'

        - expr: 'count without(instance, pod, node) (up == 0)'
          record: 'count:up0'

    - name: "general-alert.rules"
      rules:
        - alert: "TargetDown"
          expr: |
            100 * (count(up == 0) by (cluster, job, namespace, service) / count(up) by (cluster, job, namespace, service)) > 10
          for: "10m"
          labels:
            severity: "warning"
          annotations:
            summary: 'One or more targets are unreachable.'
            description: |
              {{ printf "%.4g" $value }}% of the {{ $labels.job }}/{{ $labels.service }} targets in {{ $labels.namespace }} namespace are down.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/general/targetdown'

        - alert: "KubeVersionMismatch"
          expr: |
            count by (cluster) (
                count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))
            ) > 1
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'Different semantic versions of Kubernetes components running.'
            description: 'There are {{ $value }} different semantic versions of Kubernetes components running.'
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeversionmismatch'

        - alert: "KubeDeploymentGenerationMismatch"
          expr: |
            kube_deployment_status_observed_generation{job="kube-state-metrics",namespace=~".*"}
            != kube_deployment_metadata_generation{job="kube-state-metrics",namespace=~".*"}
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'Deployment generation mismatch due to possible roll-back.'
            description: |
              Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match,
              this indicates that the Deployment has failed but has not been rolled back.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentgenerationmismatch'

        - alert: "KubeDeploymentReplicasMismatch"
          expr: |
            (
                kube_deployment_spec_replicas{job="kube-state-metrics",namespace=~".*"}
                > kube_deployment_status_replicas_available{job="kube-state-metrics",namespace=~".*"}
            ) and (
                changes(kube_deployment_status_replicas_updated{job="kube-state-metrics",namespace=~".*"}[10m]) == 0
            )
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'Deployment has not matched the expected number of replicas.'
            description: |
              Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentreplicasmismatch'

        - alert: "KubeDeploymentRolloutStuck"
          expr: |
            kube_deployment_status_condition{condition="Progressing",status="false",job="kube-state-metrics",namespace=~".*"} != 0
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'Deployment rollout is not progressing.'
            description: |
              Rollout of deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not progressing for longer than 15 minutes.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentrolloutstuck'

        - alert: "KubeStatefulSetReplicasMismatch"
          expr: |
            (
                kube_statefulset_status_replicas_ready{job="kube-state-metrics",namespace=~".*"}
                != kube_statefulset_status_replicas{job="kube-state-metrics",namespace=~".*"}
            ) and (
                changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics",namespace=~".*"}[10m]) == 0
            )
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'StatefulSet has not matched the expected number of replicas.'
            description: |
              StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetreplicasmismatch'

        - alert: "KubeStatefulSetGenerationMismatch"
          expr: |
            kube_statefulset_status_observed_generation{job="kube-state-metrics",namespace=~".*"}
            != kube_statefulset_metadata_generation{job="kube-state-metrics",namespace=~".*"}
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'StatefulSet generation mismatch due to possible roll-back.'
            description: |
              StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match,
              this indicates that the StatefulSet has failed but has not been rolled back.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetgenerationmismatch'

        - alert: "KubeStatefulSetUpdateNotRolledOut"
          expr: |
            (max without (revision) (
                kube_statefulset_status_current_revision{job="kube-state-metrics",namespace=~".*"}
                unless kube_statefulset_status_update_revision{job="kube-state-metrics",namespace=~".*"}
            ) * (
                kube_statefulset_replicas{job="kube-state-metrics",namespace=~".*"}
                != kube_statefulset_status_replicas_updated{job="kube-state-metrics",namespace=~".*"}
            )) and (
                changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics",namespace=~".*"}[5m]) == 0
            )
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'StatefulSet update has not been rolled out.'
            description: 'StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.'
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetupdatenotrolledout'

        - alert: "KubeDaemonSetRolloutStuck"
          expr: |
            ((
                kube_daemonset_status_current_number_scheduled{job="kube-state-metrics",namespace=~".*"}
                != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics",namespace=~".*"}
            )
            or (kube_daemonset_status_number_misscheduled{job="kube-state-metrics",namespace=~".*"} != 0)
            or (
                kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics",namespace=~".*"}
                != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics",namespace=~".*"}
            ) or (
                kube_daemonset_status_number_available{job="kube-state-metrics",namespace=~".*"}
                != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics",namespace=~".*"}
            )) and (
                changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics",namespace=~".*"}[5m]) == 0
            )
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'DaemonSet rollout is stuck.'
            description: |
              DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetrolloutstuck'

        - alert: "KubeDaemonSetNotScheduled"
          expr: |
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics",namespace=~".*"}
            - kube_daemonset_status_current_number_scheduled{job="kube-state-metrics",namespace=~".*"} > 0
          for: "10m"
          labels:
            severity: "warning"
          annotations:
            summary: 'DaemonSet pods are not scheduled.'
            description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.'
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetnotscheduled'

        - alert: "KubeDaemonSetMisScheduled"
          expr: 'kube_daemonset_status_number_misscheduled{job="kube-state-metrics", namespace=~".*"} > 0'
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'DaemonSet pods are misscheduled.'
            description: |
              {{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetmisscheduled'

        - alert: "KubeJobNotCompleted"
          expr: |
            time() - max by (namespace, job_name, cluster) (
                kube_job_status_start_time{job="kube-state-metrics",namespace=~".*"}
                and kube_job_status_active{job="kube-state-metrics",namespace=~".*"}
            > 0) > 43200
          labels:
            severity: "warning"
          annotations:
            summary: 'Job did not complete in time.'
            description: |
              Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobnotcompleted'

        - alert: "KubeJobFailed"
          expr: 'kube_job_failed{job="kube-state-metrics", namespace=~".*"}  > 0'
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'Job failed to complete.'
            description: |
              Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete.
              Removing failed job after investigation should clear this alert.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobfailed'

        - alert: "KubeHpaReplicasMismatch"
          expr: |
            (
                kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics",namespace=~".*"}
                != kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"})
                and (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"}
                > kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics",namespace=~".*"})
                and (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"}
                < kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics",namespace=~".*"})
                and changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"}[15m]
            ) == 0
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'HPA has not matched desired number of replicas.'
            description: |
              HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has not matched the desired number of replicas for longer than 15 minutes.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpareplicasmismatch'

        - alert: "KubeHpaMaxedOut"
          expr: |
            kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics",namespace=~".*"}
            == kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics",namespace=~".*"}
          for: "15m"
          labels:
            severity: "warning"
          annotations:
            summary: 'HPA is running at max replicas.'
            description: |
              HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has been running at max replicas for longer than 15 minutes.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpamaxedout'

        - alert: "KubePersistentVolumeFillingUp"
          expr: |
            (
                kubelet_volume_stats_available_bytes{job="kubelet",namespace=~".*",metrics_path="/metrics"}
                / kubelet_volume_stats_capacity_bytes{job="kubelet",namespace=~".*",metrics_path="/metrics"}
            ) < 0.03
            and kubelet_volume_stats_used_bytes{job="kubelet",namespace=~".*",metrics_path="/metrics"} > 0
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: "1m"
          labels:
            severity: "critical"
          annotations:
            summary: 'PersistentVolume is filling up.'
            description: |
              The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }}
              {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is only {{ $value | humanizePercentage }} free.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumefillingup'

        - alert: "KubePersistentVolumeFillingUp"
          expr: |
            (
                kubelet_volume_stats_available_bytes{job="kubelet",namespace=~".*",metrics_path="/metrics"}
                / kubelet_volume_stats_capacity_bytes{job="kubelet",namespace=~".*",metrics_path="/metrics"}
            ) < 0.15
            and kubelet_volume_stats_used_bytes{job="kubelet",namespace=~".*",metrics_path="/metrics"} > 0
            and predict_linear(kubelet_volume_stats_available_bytes{job="kubelet",namespace=~".*",metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: "1h"
          labels:
            severity: "warning"
          annotations:
            summary: 'PersistentVolume is filling up.'
            description: |
              Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }}
              {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to fill up within four days.
              Currently {{ $value | humanizePercentage }} is available.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumefillingup'

        - alert: "KubePersistentVolumeInodesFillingUp"
          expr: |
            (
                kubelet_volume_stats_inodes_free{job="kubelet",namespace=~".*",metrics_path="/metrics"}
                / kubelet_volume_stats_inodes{job="kubelet",namespace=~".*",metrics_path="/metrics"}
            ) < 0.03
            and kubelet_volume_stats_inodes_used{job="kubelet",namespace=~".*",metrics_path="/metrics"} > 0
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: "1m"
          labels:
            severity: "critical"
          annotations:
            summary: 'PersistentVolumeInodes are filling up.'
            description: |
              The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }}
              {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} only has {{ $value | humanizePercentage }} free inodes.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeinodesfillingup'

        - alert: "KubePersistentVolumeInodesFillingUp"
          expr: |
            (
                kubelet_volume_stats_inodes_free{job="kubelet",namespace=~".*",metrics_path="/metrics"}
                / kubelet_volume_stats_inodes{job="kubelet",namespace=~".*",metrics_path="/metrics"}
            ) < 0.15
            and kubelet_volume_stats_inodes_used{job="kubelet",namespace=~".*",metrics_path="/metrics"} > 0
            and predict_linear(kubelet_volume_stats_inodes_free{job="kubelet",namespace=~".*",metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{access_mode="ReadOnlyMany"} == 1
            unless on (cluster,namespace,persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: "1h"
          labels:
            severity: "warning"
          annotations:
            summary: 'PersistentVolumeInodes are filling up.'
            description: |
              Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }}
              {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to run out of inodes within four days.
              Currently {{ $value | humanizePercentage }} of its inodes are free.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeinodesfillingup'

        - alert: "KubePersistentVolumeErrors"
          expr: 'kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0'
          for: "5m"
          labels:
            severity: "critical"
          annotations:
            summary: 'PersistentVolume is having issues with provisioning.'
            description: |
              The persistent volume {{ $labels.persistentvolume }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} has status {{ $labels.phase }}.
            runbook_url: 'https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeerrors'
